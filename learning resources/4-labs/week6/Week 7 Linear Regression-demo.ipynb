{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this lab, we will implement Linear Regression using Least-square Solution. We will use the same example as we did in the class (Slide 18 from the linear regression slides). There are 5 steps. Let's implement them using only numpy step by step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![linreg_steps](linreg_slide_18.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given the dataset: {(0,0), (0,1), (1,0)} and asked to find the \\\n",
    "least-squares solution for the parameters in the regression of \\\n",
    "the function: y = w1 +w2^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape : (3, 1)\n",
      "targets shape : (3, 1)\n"
     ]
    }
   ],
   "source": [
    "# creating the input and target in numpy arrays \n",
    "inputs = np.array([[0], [0], [1]])\n",
    "targets = np.array([[0], [1], [0]])\n",
    "print('inputs shape :',np.shape(inputs))\n",
    "print('targets shape :',np.shape(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape : (3, 2)\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# now let's do the steps to find the solution  \n",
    "# Step 1: evaluate the basis on the points\n",
    "inputs = np.concatenate((np.ones((np.shape(inputs)[0],1)),inputs),axis=1)\n",
    "print('inputs shape :',np.shape(inputs))\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_matrix shape : (2, 2)\n",
      "[[3. 1.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# step 2: compute -> transpose(inputs) * inputs \n",
    "q_matrix = np.dot(np.transpose(inputs),inputs)\n",
    "print('q_matrix shape :',np.shape(q_matrix))\n",
    "print(q_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_inverse shape : (2, 2)\n",
      "[[ 0.5 -0.5]\n",
      " [-0.5  1.5]]\n"
     ]
    }
   ],
   "source": [
    "# step 3: invert q_matrix\n",
    "q_inverse = np.linalg.inv(q_matrix)\n",
    "print('q_inverse shape :',np.shape(q_inverse))\n",
    "print(q_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_pseudo shape : (2, 3)\n",
      "[[ 0.5  0.5  0. ]\n",
      " [-0.5 -0.5  1. ]]\n"
     ]
    }
   ],
   "source": [
    "# step 4: Compute the pseudo-inverse -> q_inverse * transpose(inputs)\n",
    "q_pseudo = np.dot(q_inverse,np.transpose(inputs))\n",
    "print('q_pseudo shape :',np.shape(q_pseudo))\n",
    "print(q_pseudo.astype(np.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w shape : (2, 1)\n",
      "[[ 0.5]\n",
      " [-0.5]]\n"
     ]
    }
   ],
   "source": [
    "# step 5: compute w = q_pseudo * targets\n",
    "weights = np.dot(q_pseudo,targets)\n",
    "print('w shape :',np.shape(weights))\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's implement the steps but on a real dataset. we will work on the auto-mpg dataset. This consists of a collection of a number of datapoints about certain cars (weight, horsepower, etc.), with the aim being to predict the fuel efficiency in miles per gallon (mpg) in for each car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You are asked to\n",
    "    - load the dataset text file (auto-mpg.txt) as numpy array \n",
    "    - prerocess the dataset (normalise, split it into train and test sets)\n",
    "    - find the least-squares solution for the parameters (weights vector)\n",
    "    - test the found parameters on the test set and calculate the error\n",
    "\n",
    "The following comments and codes are meant to guide you. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Please note: This dataset has one problem. There are missing values \n",
    "in it (labelled with question marks ‘?’). The np.loadtxt() method doesn’t\n",
    "like these, and we don’t know what to do with them, anyway,manually edit \n",
    "the file and delete all lines where there is a ? in that line. The linear\n",
    "regressor can’t do much with the names of the cars either, but since they \n",
    "appear in quotes(\") we will tell np.loadtxt that they are comments\n",
    "\n",
    "\n",
    "Below are the attribute Information for the dataset:\n",
    "\n",
    "    1. mpg:           continuous \n",
    "    2. cylinders:     multi-valued discrete\n",
    "    3. displacement:  continuous\n",
    "    4. horsepower:    continuous\n",
    "    5. weight:        continuous\n",
    "    6. acceleration:  continuous\n",
    "    7. model year:    multi-valued discrete\n",
    "    8. origin:        multi-valued discrete\n",
    "    9. car name:      string (unique for each instance)\n",
    "\n",
    "Please note: the first column is our target (mpg)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shengdaolin_sh/dir_install/Aanconda3/anaconda3/envs/ml_env/lib/python3.6/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>18.0</th>\n",
       "      <th>8</th>\n",
       "      <th>307.0</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>130.0</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>3504.</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>12.0</th>\n",
       "      <th>70  1\\t\"chevrolet chevelle malibu\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70  1\\t\"buick skylark 320\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70  1\\t\"plymouth satellite\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70  1\\t\"amc rebel sst\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70  1\\t\"ford torino\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>429.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4341.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70  1\\t\"ford galaxie 500\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   18.0  8  307.0  Unnamed: 3  130.0  Unnamed: 5   3504.  Unnamed: 7  12.0  \\\n",
       "0  15.0  8  350.0         NaN  165.0         NaN  3693.0         NaN  11.5   \n",
       "1  18.0  8  318.0         NaN  150.0         NaN  3436.0         NaN  11.0   \n",
       "2  16.0  8  304.0         NaN  150.0         NaN  3433.0         NaN  12.0   \n",
       "3  17.0  8  302.0         NaN  140.0         NaN  3449.0         NaN  10.5   \n",
       "4  15.0  8  429.0         NaN  198.0         NaN  4341.0         NaN  10.0   \n",
       "\n",
       "  70  1\\t\"chevrolet chevelle malibu\"  \n",
       "0         70  1\\t\"buick skylark 320\"  \n",
       "1        70  1\\t\"plymouth satellite\"  \n",
       "2             70  1\\t\"amc rebel sst\"  \n",
       "3               70  1\\t\"ford torino\"  \n",
       "4          70  1\\t\"ford galaxie 500\"  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: load the dataset file using np.loadtxt()\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"auto-mpg.txt\", delimiter='   ')\n",
    "df.head()\n",
    "# data = np.loadtxt(\"auto-mpg.txt\", delimiter=' ', usecols=range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalise the dataset. You can do this easily in numpy \n",
    "# by using np.mean and np.var. The only place where care is needed \n",
    "# is along which axis the mean and variance are computed: \n",
    "# axis=0 sums down the columns and axis=1 sums across the rows.\n",
    "\n",
    "normalised_date = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Now separate the data into training and testing sets,\n",
    "\n",
    "training, testing = None, None \n",
    "\n",
    "# And split each set into inputs and targets hint: slicing the array\n",
    "trainin, traintgt = None, None\n",
    "testin, testtgt = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the training set to find the weights vector.\n",
    "# you need to implement the previous 5 steps on the training set \n",
    "# and find the weights vector (this is called training).  \n",
    "# To make it simple we define a function that takes \n",
    "# two args: inputs and targets and return the weights vector\n",
    "\n",
    "def linreg(inputs,targets):\n",
    "    # you should implement the 5 steps here\n",
    "    \n",
    "    weights = None\n",
    "\n",
    "    \n",
    "    return weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your implementation \n",
    "weights = linreg(trainin,traintgt) \n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Testing the found weights on the testing set \n",
    "# you can do this by \n",
    "#     - testout = (testin*weights)\n",
    "#     - error = sum((testout - testtgt)**2)\n",
    "\n",
    "testout = None\n",
    "error = None \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    You can try to re-train the model without the normalising the data \n",
    "    and see if this makes any different on the error value\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
