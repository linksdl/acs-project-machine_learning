{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this lab, we will go through the K-means algorithm in the figure below using only NumPy library. We will test the implmentation on the Iris dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![k-means algorithm](k-means.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n",
      "[[5.1 3.5 1.4 0.2 0. ]\n",
      " [4.9 3.  1.4 0.2 0. ]\n",
      " [4.7 3.2 1.3 0.2 0. ]\n",
      " [4.6 3.1 1.5 0.2 0. ]\n",
      " [5.  3.6 1.4 0.2 0. ]\n",
      " [5.4 3.9 1.7 0.4 0. ]\n",
      " [4.6 3.4 1.4 0.3 0. ]\n",
      " [5.  3.4 1.5 0.2 0. ]\n",
      " [4.4 2.9 1.4 0.2 0. ]\n",
      " [4.9 3.1 1.5 0.1 0. ]\n",
      " [5.4 3.7 1.5 0.2 0. ]\n",
      " [4.8 3.4 1.6 0.2 0. ]\n",
      " [4.8 3.  1.4 0.1 0. ]\n",
      " [4.3 3.  1.1 0.1 0. ]\n",
      " [5.8 4.  1.2 0.2 0. ]\n",
      " [5.7 4.4 1.5 0.4 0. ]\n",
      " [5.4 3.9 1.3 0.4 0. ]\n",
      " [5.1 3.5 1.4 0.3 0. ]\n",
      " [5.7 3.8 1.7 0.3 0. ]\n",
      " [5.1 3.8 1.5 0.3 0. ]\n",
      " [5.4 3.4 1.7 0.2 0. ]\n",
      " [5.1 3.7 1.5 0.4 0. ]\n",
      " [4.6 3.6 1.  0.2 0. ]\n",
      " [5.1 3.3 1.7 0.5 0. ]\n",
      " [4.8 3.4 1.9 0.2 0. ]\n",
      " [5.  3.  1.6 0.2 0. ]\n",
      " [5.  3.4 1.6 0.4 0. ]\n",
      " [5.2 3.5 1.5 0.2 0. ]\n",
      " [5.2 3.4 1.4 0.2 0. ]\n",
      " [4.7 3.2 1.6 0.2 0. ]\n",
      " [4.8 3.1 1.6 0.2 0. ]\n",
      " [5.4 3.4 1.5 0.4 0. ]\n",
      " [5.2 4.1 1.5 0.1 0. ]\n",
      " [5.5 4.2 1.4 0.2 0. ]\n",
      " [4.9 3.1 1.5 0.1 0. ]\n",
      " [5.  3.2 1.2 0.2 0. ]\n",
      " [5.5 3.5 1.3 0.2 0. ]\n",
      " [4.9 3.1 1.5 0.1 0. ]\n",
      " [4.4 3.  1.3 0.2 0. ]\n",
      " [5.1 3.4 1.5 0.2 0. ]\n",
      " [5.  3.5 1.3 0.3 0. ]\n",
      " [4.5 2.3 1.3 0.3 0. ]\n",
      " [4.4 3.2 1.3 0.2 0. ]\n",
      " [5.  3.5 1.6 0.6 0. ]\n",
      " [5.1 3.8 1.9 0.4 0. ]\n",
      " [4.8 3.  1.4 0.3 0. ]\n",
      " [5.1 3.8 1.6 0.2 0. ]\n",
      " [4.6 3.2 1.4 0.2 0. ]\n",
      " [5.3 3.7 1.5 0.2 0. ]\n",
      " [5.  3.3 1.4 0.2 0. ]\n",
      " [7.  3.2 4.7 1.4 1. ]\n",
      " [6.4 3.2 4.5 1.5 1. ]\n",
      " [6.9 3.1 4.9 1.5 1. ]\n",
      " [5.5 2.3 4.  1.3 1. ]\n",
      " [6.5 2.8 4.6 1.5 1. ]\n",
      " [5.7 2.8 4.5 1.3 1. ]\n",
      " [6.3 3.3 4.7 1.6 1. ]\n",
      " [4.9 2.4 3.3 1.  1. ]\n",
      " [6.6 2.9 4.6 1.3 1. ]\n",
      " [5.2 2.7 3.9 1.4 1. ]\n",
      " [5.  2.  3.5 1.  1. ]\n",
      " [5.9 3.  4.2 1.5 1. ]\n",
      " [6.  2.2 4.  1.  1. ]\n",
      " [6.1 2.9 4.7 1.4 1. ]\n",
      " [5.6 2.9 3.6 1.3 1. ]\n",
      " [6.7 3.1 4.4 1.4 1. ]\n",
      " [5.6 3.  4.5 1.5 1. ]\n",
      " [5.8 2.7 4.1 1.  1. ]\n",
      " [6.2 2.2 4.5 1.5 1. ]\n",
      " [5.6 2.5 3.9 1.1 1. ]\n",
      " [5.9 3.2 4.8 1.8 1. ]\n",
      " [6.1 2.8 4.  1.3 1. ]\n",
      " [6.3 2.5 4.9 1.5 1. ]\n",
      " [6.1 2.8 4.7 1.2 1. ]\n",
      " [6.4 2.9 4.3 1.3 1. ]\n",
      " [6.6 3.  4.4 1.4 1. ]\n",
      " [6.8 2.8 4.8 1.4 1. ]\n",
      " [6.7 3.  5.  1.7 1. ]\n",
      " [6.  2.9 4.5 1.5 1. ]\n",
      " [5.7 2.6 3.5 1.  1. ]\n",
      " [5.5 2.4 3.8 1.1 1. ]\n",
      " [5.5 2.4 3.7 1.  1. ]\n",
      " [5.8 2.7 3.9 1.2 1. ]\n",
      " [6.  2.7 5.1 1.6 1. ]\n",
      " [5.4 3.  4.5 1.5 1. ]\n",
      " [6.  3.4 4.5 1.6 1. ]\n",
      " [6.7 3.1 4.7 1.5 1. ]\n",
      " [6.3 2.3 4.4 1.3 1. ]\n",
      " [5.6 3.  4.1 1.3 1. ]\n",
      " [5.5 2.5 4.  1.3 1. ]\n",
      " [5.5 2.6 4.4 1.2 1. ]\n",
      " [6.1 3.  4.6 1.4 1. ]\n",
      " [5.8 2.6 4.  1.2 1. ]\n",
      " [5.  2.3 3.3 1.  1. ]\n",
      " [5.6 2.7 4.2 1.3 1. ]\n",
      " [5.7 3.  4.2 1.2 1. ]\n",
      " [5.7 2.9 4.2 1.3 1. ]\n",
      " [6.2 2.9 4.3 1.3 1. ]\n",
      " [5.1 2.5 3.  1.1 1. ]\n",
      " [5.7 2.8 4.1 1.3 1. ]\n",
      " [6.3 3.3 6.  2.5 2. ]\n",
      " [5.8 2.7 5.1 1.9 2. ]\n",
      " [7.1 3.  5.9 2.1 2. ]\n",
      " [6.3 2.9 5.6 1.8 2. ]\n",
      " [6.5 3.  5.8 2.2 2. ]\n",
      " [7.6 3.  6.6 2.1 2. ]\n",
      " [4.9 2.5 4.5 1.7 2. ]\n",
      " [7.3 2.9 6.3 1.8 2. ]\n",
      " [6.7 2.5 5.8 1.8 2. ]\n",
      " [7.2 3.6 6.1 2.5 2. ]\n",
      " [6.5 3.2 5.1 2.  2. ]\n",
      " [6.4 2.7 5.3 1.9 2. ]\n",
      " [6.8 3.  5.5 2.1 2. ]\n",
      " [5.7 2.5 5.  2.  2. ]\n",
      " [5.8 2.8 5.1 2.4 2. ]\n",
      " [6.4 3.2 5.3 2.3 2. ]\n",
      " [6.5 3.  5.5 1.8 2. ]\n",
      " [7.7 3.8 6.7 2.2 2. ]\n",
      " [7.7 2.6 6.9 2.3 2. ]\n",
      " [6.  2.2 5.  1.5 2. ]\n",
      " [6.9 3.2 5.7 2.3 2. ]\n",
      " [5.6 2.8 4.9 2.  2. ]\n",
      " [7.7 2.8 6.7 2.  2. ]\n",
      " [6.3 2.7 4.9 1.8 2. ]\n",
      " [6.7 3.3 5.7 2.1 2. ]\n",
      " [7.2 3.2 6.  1.8 2. ]\n",
      " [6.2 2.8 4.8 1.8 2. ]\n",
      " [6.1 3.  4.9 1.8 2. ]\n",
      " [6.4 2.8 5.6 2.1 2. ]\n",
      " [7.2 3.  5.8 1.6 2. ]\n",
      " [7.4 2.8 6.1 1.9 2. ]\n",
      " [7.9 3.8 6.4 2.  2. ]\n",
      " [6.4 2.8 5.6 2.2 2. ]\n",
      " [6.3 2.8 5.1 1.5 2. ]\n",
      " [6.1 2.6 5.6 1.4 2. ]\n",
      " [7.7 3.  6.1 2.3 2. ]\n",
      " [6.3 3.4 5.6 2.4 2. ]\n",
      " [6.4 3.1 5.5 1.8 2. ]\n",
      " [6.  3.  4.8 1.8 2. ]\n",
      " [6.9 3.1 5.4 2.1 2. ]\n",
      " [6.7 3.1 5.6 2.4 2. ]\n",
      " [6.9 3.1 5.1 2.3 2. ]\n",
      " [5.8 2.7 5.1 1.9 2. ]\n",
      " [6.8 3.2 5.9 2.3 2. ]\n",
      " [6.7 3.3 5.7 2.5 2. ]\n",
      " [6.7 3.  5.2 2.3 2. ]\n",
      " [6.3 2.5 5.  1.9 2. ]\n",
      " [6.5 3.  5.2 2.  2. ]\n",
      " [6.2 3.4 5.4 2.3 2. ]\n",
      " [5.9 3.  5.1 1.8 2. ]]\n"
     ]
    }
   ],
   "source": [
    "# load the Iris data \n",
    "iris = np.loadtxt('iris_proc.data',delimiter=',')\n",
    "print(iris.shape)\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's shuffle the data set\n",
    "np.random.shuffle(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into Xtrain, ytrain, Xtest, ytest\n",
    "X = iris[:,:4]\n",
    "y = iris[:,4:]\n",
    "num_train = 120 # number of train samples 120 for training and 30 for testing\n",
    "Xtrain, Xtest = X[:num_train], X[num_train:]\n",
    "ytrain, ytest = y[:num_train], y[num_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 : initialisation  \n",
    "\n",
    "nData = np.shape(Xtrain)[0] # number data samples \n",
    "nDim = np.shape(Xtrain)[1] # number of features \n",
    "# lets initialize the k to be 3 since we know the number of classes already\n",
    "k = 3 \n",
    "nData, nDim, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20258733 0.99525039 0.78898835 0.46682883]\n",
      " [0.85144455 0.60679562 0.0451325  0.98271295]\n",
      " [0.903942   0.02029594 0.82332333 0.65637917]]\n"
     ]
    }
   ],
   "source": [
    "# choosing k random positions in the imput space \n",
    "# Note: we multiply the initialised centers position by(maxima-minima) to be within the data manifold \n",
    "minima = Xtrain.min(axis=0)\n",
    "maxima = Xtrain.max(axis=0)\n",
    "centres = np.random.rand(k, nDim)*(maxima-minima)+minima \n",
    "oldCentres = np.random.rand(k, nDim)# To copy the centers while training *(maxima-minima)+minima\n",
    "print(oldCentres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 : Learning \n",
    "\n",
    "# maximum iteration for training (repeat updating the cluster centres) \n",
    "maxIterations=2 # lets start with 2\n",
    "count = 0 # a variable to count how many the number of iteration  \n",
    "\n",
    "# here the while loop will stop when either we reach the number of mxIteration or \n",
    "# the cluster centers stop moving \n",
    "while np.sum(np.sum(oldCentres-centres)) != 0 and count < maxIterations:\n",
    "\n",
    "    oldCentres = centres.copy()\n",
    "    count += 1\n",
    "\n",
    "    # Compute distances\n",
    "    distances = np.ones((1,nData)) * np.sum((Xtrain-centres[0,:])**2,axis=1)\n",
    "    for j in range(k-1):\n",
    "        distances = np.append(distances,np.ones((1,nData))*np.sum((Xtrain - centres[j+1,:])**2,axis=1),axis=0)\n",
    "    \n",
    "    \n",
    "    # Identify the closest cluster\n",
    "    cluster = distances.argmin(axis=0)\n",
    "    cluster = np.transpose(cluster*np.ones((1,nData)))\n",
    "    \n",
    "    \n",
    "    # Update the cluster centres\t\n",
    "    for j in range(k):\n",
    "        thisCluster = np.where(cluster==j,1,0)\n",
    "        if sum(thisCluster)>0:\n",
    "            centres[j,:] = np.sum(Xtrain*thisCluster,axis=0) / np.sum(thisCluster)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centres positions are \n",
      " [[5.60991098 3.07207999 6.69968303 0.13158718]\n",
      " [5.00952381 3.4047619  1.45238095 0.24047619]\n",
      " [6.26025641 2.86923077 4.85384615 1.64230769]]\n"
     ]
    }
   ],
   "source": [
    "print('centres positions are \\n', centres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Usage\n",
    "\n",
    "num_test = np.shape(Xtest)[0]\n",
    "# Compute distances\n",
    "distances = np.ones((1,num_test))*np.sum((Xtest-centres[0,:])**2,axis=1)\n",
    "for j in range(k-1):\n",
    "    distances = np.append(distances,np.ones((1,num_test))*np.sum((Xtest-centres[j+1,:])**2,axis=1),axis=0)\n",
    "\n",
    "# Identify the closest cluster\n",
    "cluster = distances.argmin(axis=0)\n",
    "cluster = np.transpose(cluster*np.ones((1,num_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 2. 2. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(cluster[:10].ravel())\n",
    "print(ytest[:10].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we know if the k-means learned to cluster the dataset correctly?\n",
    "# We can evaluate the model by examining if the model learns to cluster \n",
    "# test samples of a single class into the same cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Can you train the model for more number of iterations? will you get a better result? \n",
    "# Note: don't run the data split cells again for comparision "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
