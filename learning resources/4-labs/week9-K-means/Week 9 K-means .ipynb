{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this lab, we will go through the K-means algorithm in the figure below using only NumPy library. We will test the implmentation on the Iris dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![k-means algorithm](k-means.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    }
   ],
   "source": [
    "# load the Iris data \n",
    "iris = np.loadtxt('iris_proc.data',delimiter=',')\n",
    "print(iris.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's shuffle the data set\n",
    "np.random.shuffle(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into Xtrain, ytrain, Xtest, ytest\n",
    "X = iris[:,:4]\n",
    "y = iris[:,4:]\n",
    "num_train = 120 # number of train samples 120 for training and 30 for testing\n",
    "Xtrain, Xtest = X[:num_train], X[num_train:]\n",
    "ytrain, ytest = y[:num_train], y[num_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 : initialisation  \n",
    "\n",
    "nData = np.shape(Xtrain)[0] # number data samples \n",
    "nDim = np.shape(Xtrain)[1] # number of features \n",
    "# lets initialize the k to be 3 since we know the number of classes already\n",
    "k = 3 \n",
    "nData, nDim, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing k random positions in the imput space \n",
    "# Note: we multiply the initialised centers position by(maxima-minima) to be within the data manifold \n",
    "minima = Xtrain.min(axis=0)\n",
    "maxima = Xtrain.max(axis=0)\n",
    "centres = np.random.rand(k, nDim)*(maxima-minima)+minima \n",
    "oldCentres = np.random.rand(k, nDim)# To copy the centers while training *(maxima-minima)+minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 : Learning \n",
    "\n",
    "# maximum iteration for training (repeat updating the cluster centres) \n",
    "maxIterations=2 # lets start with 2\n",
    "count = 0 # a variable to count how many the number of iteration  \n",
    "\n",
    "# here the while loop will stop when either we reach the number of mxIteration or \n",
    "# the cluster centers stop moving \n",
    "while np.sum(np.sum(oldCentres-centres))!= 0 and count<maxIterations:\n",
    "\n",
    "    oldCentres = centres.copy()\n",
    "    count += 1\n",
    "\n",
    "    # Compute distances\n",
    "    distances = np.ones((1,nData))*np.sum((Xtrain-centres[0,:])**2,axis=1)\n",
    "    for j in range(k-1):\n",
    "        distances = np.append(distances,np.ones((1,nData))*np.sum((Xtrain - centres[j+1,:])**2,axis=1),axis=0)\n",
    "    \n",
    "    \n",
    "    # Identify the closest cluster\n",
    "    cluster = distances.argmin(axis=0)\n",
    "    cluster = np.transpose(cluster*np.ones((1,nData)))\n",
    "    \n",
    "    \n",
    "    # Update the cluster centres\t\n",
    "    for j in range(k):\n",
    "        thisCluster = np.where(cluster==j,1,0)\n",
    "        if sum(thisCluster)>0:\n",
    "            centres[j,:] = np.sum(Xtrain*thisCluster,axis=0)/np.sum(thisCluster)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centres positions are \n",
      " [[5.01707317 3.4097561  1.50243902 0.26341463]\n",
      " [6.65142857 2.99142857 5.64285714 2.04571429]\n",
      " [5.96818182 2.75909091 4.29318182 1.33181818]]\n"
     ]
    }
   ],
   "source": [
    "print('centres positions are \\n', centres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Usage\n",
    "\n",
    "num_test = np.shape(Xtest)[0]\n",
    "# Compute distances\n",
    "distances = np.ones((1,num_test))*np.sum((Xtest-centres[0,:])**2,axis=1)\n",
    "for j in range(k-1):\n",
    "    distances = np.append(distances,np.ones((1,num_test))*np.sum((Xtest-centres[j+1,:])**2,axis=1),axis=0)\n",
    "\n",
    "# Identify the closest cluster\n",
    "cluster = distances.argmin(axis=0)\n",
    "cluster = np.transpose(cluster*np.ones((1,num_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. 2. 0. 0. 0. 2. 0. 2.]\n",
      "[2. 0. 2. 1. 0. 0. 0. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(cluster[:10].ravel())\n",
    "print(ytest[:10].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we know if the k-means learned to cluster the dataset correctly?\n",
    "# We can evaluate the model by examining if the model learns to cluster \n",
    "# test samples of a single class into the same cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Can you train the model for more number of iterations? will you get a better result? \n",
    "# Note: don't run the data split cells again for comparision "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
